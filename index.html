<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>VLM Datasets</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
        }
        h1 {
            color: #2c3e50;
            border-bottom: 2px solid #3498db;
            padding-bottom: 10px;
        }
        h2 {
            color: #2980b9;
        }
        .dataset {
            background-color: #f9f9f9;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            margin-bottom: 20px;
        }
        .dataset h3 {
            margin-top: 0;
            color: #16a085;
        }
        .dataset p {
            margin-bottom: 10px;
        }
        .dataset a {
            color: #3498db;
            text-decoration: none;
        }
        .dataset a:hover {
            text-decoration: underline;
        }
    </style>
</head>
<body>
    <h1>VLM Datasets</h1>
    <p>A collection of datasets for Vision Language Models (Image captions, OCR, Knowledge etc)</p>
    
    <h2>Available Datasets</h2>
    
    <div class="dataset">
        <h3>WIT (Wikipedia-based Image Text) Dataset</h3>
        <p><strong>Type:</strong> Knowledge</p>
        <p><strong>Size:</strong> 7,371,471 image-text pairs</p>
        <p><strong>Languages:</strong> English, Russian, Turkish, Kazakh</p>
        <p><strong>Description:</strong> A large multimodal dataset based on Wikipedia, containing image-text pairs with rich metadata.</p>
        <p><strong>More Info:</strong> <a href="wit_dataset.html">WIT Dataset Details</a></p>
    </div>
    
    <!-- Add more dataset entries as needed -->
    
    <footer>
        <p>For more information, please visit the <a href="https://github.com/CCRss/VLM_datasets">GitHub repository</a>.</p>
    </footer>
</body>
</html>
